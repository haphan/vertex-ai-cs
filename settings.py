from pydantic import BaseModel
from pydantic_settings import BaseSettings, SettingsConfigDict


class PromptTemplateModel(BaseModel):
    system: str ="""
T√¥i l√† Linh, nh√¢n vi√™n chƒÉm s√≥c kh√°ch h√†ng.
T√¥i ch·ªâ tr·∫£ l·ªùi nh·ªØng c√¢u h·ªèi c√≥ li√™n quan ƒë·∫øn ng·ªØ c·∫£nh hi·ªán t·∫°i.
N·∫øu c√¢u h·ªèi kh√¥ng li√™n quan, t√¥i s·∫Ω y√™u c·∫ßu kh√°ch h√†ng ƒë·∫∑t l·∫°i c√¢u h·ªèi r√µ h∆°n.
T√¥i kh√¥ng cung c·∫•p ƒë∆∞·ªùng d·∫´n ƒë·∫øn trang web.
C√¢u tr·∫£ l·ªùi c·ªßa t√¥i ph·∫£i lu√¥n ng·∫Øn g·ªçn, kh√¥ng qu√° 200 ch·ªØ.
T√¥i lu√¥n l·ªãch s·ª±, k·∫øt th√∫c c√¢u tr·∫£ l·ªùi b·∫±ng l·ªùi c·∫£m ∆°n.
T√¥i g·ªçi kh√°ch h√†ng b·∫±ng "anh/ch·ªã".
T√¥i s·ª≠ d·ª•ng emoji trong t·∫•t c·∫£ c√°c c√¢u tr·∫£ l·ªùi.
"""
    default_no_answer: str = 'D·∫°, em ch∆∞a c√≥ th√¥ng tin v·ªÅ c√¢u h·ªèi n√†y.'
    
class Settings(BaseSettings):
    model_config = SettingsConfigDict(env_file='.env', env_file_encoding='utf-8')

    llm_model_embedding: str = 'textembedding-gecko-multilingual@latest'
    llm_model_chat: str = 'chat-bison'
    llm_max_output_tokens: int = 1024
    llm_temperature:float = 0.01
    llm_top_p: float = 0.95 
    llm_top_k: int = 40

    trust_score_min: float = 0.75

    pinecone_api_key: str
    pinecone_env: str
    pinecone_idx: str

    streamlit_page_title: str = 'OnPoint Customer Service'
    streamlit_header: str = 'OnPoint Customer Service ü¶∏ ü¶∏‚Äç‚ôÄÔ∏è'
    streamlit_welcome_msg: str = 'Em l√† Linh - nh√¢n vi√™n h·ªó tr·ª£ cho OnPoint. Em c√≥ th·ªÉ gi√∫p g√¨ cho anh/ch·ªã?'
    
    prompt_template: PromptTemplateModel = PromptTemplateModel()


