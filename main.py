import os
from dotenv import load_dotenv
import streamlit as st
# from streamlit_chat import message
from utils import *
from langchain.chat_models import ChatVertexAI
from langchain.chains import ConversationChain
from langchain.chains.conversation.memory import ConversationBufferWindowMemory
from langchain.prompts import (
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
    ChatPromptTemplate,
    MessagesPlaceholder
)
load_dotenv()

#Page Config
st.set_page_config(
     layout="wide",
     page_title="JS Lab",
     page_icon="https://api.dicebear.com/5.x/bottts-neutral/svg?seed=gptLAb"
)

#Sidebar
# st.sidebar.header("OnPoint Cu")
# st.sidebar.markdown(
#     "A place for me to experiment different LLM use cases, models, application frameworks and etc."
# )

#Main Page and Chatbot components
st.title("OnPoint Avenger CS team ü¶∏‚Äç‚ôÄÔ∏è")

if 'responses' not in st.session_state:
    st.session_state['responses'] = ["Xin ch√†o! Em l√† Linh - nh√¢n vi√™n h·ªó tr·ª£ c·ªßa OnPoint. Em gi√∫p ƒë∆∞·ª£c g√¨ cho anh/ch·ªã?"]

if 'requests' not in st.session_state:
    st.session_state['requests'] = []

llm = ChatVertexAI(model_name="chat-bison-32k")
if 'buffer_memory' not in st.session_state:
            st.session_state.buffer_memory=ConversationBufferWindowMemory(k=3,return_messages=True)

system_msg_template = SystemMessagePromptTemplate.from_template(template="""
B·∫°n t√™n l√† Linh v√† l√† nh√¢n vi√™n chƒÉm s√≥c h·ªó tr·ª£ kh√°ch h√†ng c·ªßa nh√£n h√†ng OnPoint h·ªó tr·ª£ c√°c nh√£n h√†ng nh∆∞ Johnson & Johnson, Obagi, Listerine. 

Kh√¥ng ƒë∆∞·ª£c n√≥i m√¨nh l√† tr·ª£ l√Ω ·∫£o.

Tr·∫£ l·ªùi trung th·ª±c nh·∫•t v·ªÅ th√¥ng tin c·ªßa s·∫£n ph·∫©m. Kh√¥ng t∆∞ v·∫•n cho kh√°ch h√†ng v·ªÅ th√¥ng tin s·∫£n ph·∫©m kh√¥ng c√≥ trong danh m·ª•c s·∫£n ph·∫©m. Kh√¥ng ƒë∆∞a ƒë∆∞·ªùng d·∫´n t·ªõi web website n√†o trong c√¢u tr·∫£ l·ªùi. 

C√¢u tr·∫£ l·ªùi c·ªßa b·∫°n ph·∫£i lu√¥n l·ªãch s·ª±, b·∫Øt ƒë·∫ßu c√¢u tr·∫£ l·ªùi b·∫±ng "d·∫°". K·∫øt th√∫c c√¢u tr·∫£ l·ªùi b·∫±ng c√°m ∆°n. G·ªçi ng∆∞·ªùi h·ªèi b·∫±ng anh/ch·ªã.
S·ª≠ d·ª•ng emoji trong c√¢u tr·∫£ l·ªùi.

C√¢u tr·∫£ l·ªùi n√™n ng·∫Øn g·ªçn v√† kh√¥ng n√™n d√†i qu√° 200 ch·ªØ.
'""")
human_msg_template = HumanMessagePromptTemplate.from_template(template="{input}")
prompt_template = ChatPromptTemplate.from_messages([system_msg_template, MessagesPlaceholder(variable_name="history"), human_msg_template])
conversation = ConversationChain(memory=st.session_state.buffer_memory, prompt=prompt_template, llm=llm, verbose=True)

response_container = st.container()
textcontainer = st.container()

if 'something' not in st.session_state:
    st.session_state.something = ''

def submit():
    st.session_state.something = st.session_state.input
    st.session_state.input = ''

with textcontainer:
    query = st.text_input("C√¢u h·ªèi: ", key="input", on_change=submit)

    submitted_query = st.session_state.something

    if submitted_query:
        st.session_state.requests.append(submitted_query)

        with st.spinner("ƒêang tr·∫£ l·ªùi..."):
            conversation_history = get_conversation_history()
            refined_query = query_refiner(conversation_history, submitted_query)
            # st.subheader("Refined Query:")
            # st.write(refined_query)
            context = find_match(refined_query)
            response = conversation.predict(input=f"Context:\n {context} \n\n Query:\n{submitted_query}")
        
        st.session_state.responses.append(response) 

with response_container:
    if st.session_state['responses']:

        for i in range(len(st.session_state['responses'])):
            with st.chat_message(name='ai', avatar='https://i.imgur.com/O7jZFEx.jpg'):
                st.write(st.session_state['responses'][i])
            if i < len(st.session_state['requests']):
                # message(st.session_state["requests"][i], is_user=True,key=str(i)+ '_user')
                with st.chat_message(name='human'):
                    st.write(st.session_state["requests"][i])
